<!DOCTYPE html>
<html lang="en">
<head><meta charset="UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>TEAM 35: Project Proposal</title>
<link rel="stylesheet" href="styles.css">
</head>
<header>
<h1>CS7641 ML - TEAM 35: Project Proposal</h1>
<p class="team-members">Team Members: Rachit Chadha, Khalid Shaik, Mini Jain, Asmit Kumar Singh, Amrit Khera</p>
</header>
<section id="introduction">
<h2>Introduction/Background</h2>
<p>We have all experienced the curiosity that arises while watching anime, pondering the true meaning of the text displayed within the episodes. Textual visuals are frequently employed in anime to introduce new episodes, conclude existing ones, or transition between different storylines, as illustrated in the figure below. These textual elements play a pivotal role in the overall viewing experience. Therefore, it would be immensely beneficial if this text could be seamlessly translated and integrated into the video, preserving its original style, including factors like color and font, while altering the content itself.
</p>
<p>The potential applications of solving this challenge extend beyond anime. It encompasses translating movie or show posters effortlessly into the desired language, making real-time text translations accessible while exploring new places or shopping.		
</p>
</section>
<section id="problem-definition">
<h2>Problem Definition</h2>
<p>The primary objective of this project is to transform a provided Japanese image, including posters, anime frames, or images from real-world scenarios, into an English counterpart while preserving the essence, meaning, and visual style of the original image. For a visual representation of this process, please refer to the figure below. This intricate challenge can be deconstructed as a pipeline of multiple steps as shown here.
</p>
<p>The OCR and translation models have been a center of many research problems, and hence is a problem not worth exploring, since there is no significant improvement in this aspect left .The primary objective of the text eraser model is to detect and remove any textual elements within the image, subsequently filling the void seamlessly to maintain the image's integrity.  The text-inpainting and text-erasure is also a solved problem. Below you can see DALLE performing the task efficiently. There exist other mathematical models like Naive Strokes, Fast marching and techniques like FSR.<add models and references >. Hence the primary focus of our project would be on the Inter Language font transfer model.
</p>
</section>
<section id="methods">
<h2>Methods</h2>
<p>As we are attempting a novel problem...</p>
</section>
<section id="results-discussion">
<h2>Potential Results and Discussion</h2>
<p>A good way to talk about potential results is to discuss about what type of quantitative metrics...</p>
</section>
<section id="references">
<h2>References</h2>
<ol>
<li>[1] It should be noted that our approach can be trained for any language pair...</li>
<li>[2] <a href="https://lens.google.com/">Google Lens</a></li>
<!-- Add more references here -->
</ol>
</section>
<section id="timeline">
<h2>Proposed Timeline</h2>
<p>Placeholder for Gantt Chart.</p>
</section>
<section id="contribution-table">
<h2>Contribution Table</h2>
<p>Placeholder for Contribution Table.</p>
</section>
<section id="checkpoint">
<h2>Checkpoint</h2>
<p>You are required to have your dataset ready when you submit your proposal.</p>
</section>
<section id="presentation">
<h2>Presentation</h2>
<p>Placeholder for video presentation link.</p>
</section>
<footer>
<p>Authors : Rachit Chadha, Khalid Shaik, Mini Jain, Asmit Kumar Singh, Amrit Khera @Georgia Tech</p>
</footer>
</body>
</html>